# Vanguard CX Analytics Team Project

## Project Overview

In this project, we analyzed the results of an A/B test conducted by Vanguard, a leading investment management company. The primary goal was to assess whether a new user interface (UI) design improved client experience and process completion rates. Our work focused on performing exploratory data analysis (EDA), hypothesis testing, and experiment evaluation to draw conclusions about the impact of the redesigned UI.

## What We Did

### 1. **Data Exploration and Cleaning**
   - We started by exploring the provided datasets using **Pandas**, **Matplotlib**, and **Seaborn** to identify patterns, trends, and any issues in the data.
   - We cleaned the datasets by addressing missing values, removing duplicates, and handling inconsistencies that could affect the quality of our analysis.

### 2. **Defining and Calculating Performance Metrics**
   - We defined key performance indicators (KPIs) for the analysis, including:
     - **Completion rates**: To measure the proportion of clients who completed the process.
     - **Time spent on each step**: To evaluate how long clients took to complete each step in the process.
     - **Error rates**: To assess how often clients encountered issues.
   - We calculated these metrics to gain insights into how the different groups performed throughout the test.

### 3. **Hypothesis Testing**
   - We compared the **Test** and **Control** groups using an **A/B test** to analyze the differences in completion rates.
   - We also conducted additional tests to explore the influence of factors such as **age**, **gender**, and **client tenure** on completion rates.
   - We applied statistical methods, such as the **Two-proportion Z-test**, to evaluate whether the differences in outcomes between the two groups were statistically significant.

### 4. **Experiment Evaluation**
   - We evaluated the design of the experiment, focusing on randomization, potential biases, and the duration of the test.
   - Based on our findings, we recommended further steps for improving future experiment designs and data collection practices.

### 5. **Visualization**
   - We created **interactive visualizations** using **Tableau** to present the key findings from the experiment and facilitate easier interpretation of the results.
   - Additionally, we developed **Streamlit** web applications to provide real-time, interactive access to the data and analysis.

## Deliverables

- A comprehensive **analysis report** that details the findings, conclusions, and recommendations based on our investigation.
- A **Tableau dashboard** visualizing key insights from the A/B test results.
- **Jupyter notebooks** containing the code used for data exploration, hypothesis testing, and evaluation.
- A thorough **README** explaining the methodology, results, and conclusions of the project.
- A **project presentation** summarizing the main findings and insights.

## The Team

- **Constanza**
- **Bru**