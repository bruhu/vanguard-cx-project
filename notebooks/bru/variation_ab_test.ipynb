{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **A/B Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing the results of an A/B test (where you compare two versions of a product or design), you're required to ensure that the new design (let's call it \"Version B\") improves the completion rate by at least 5% compared to the current version (Version A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../../data/clean/test_variation_df_clean.csv')\n",
    "control_df = pd.read_csv('../../data/clean/control_variation_df_clean.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove duplicates and fix completion_count if necessary\n",
    "test_df_cleaned = test_df.drop_duplicates(subset=['client_id', 'visitor_id'])\n",
    "control_df_cleaned = control_df.drop_duplicates(subset=['client_id', 'visitor_id'])\n",
    "\n",
    "# Ensure completion_count is binary (0 or 1) using .loc for safe assignment\n",
    "test_df_cleaned.loc[:, 'completion_count'] = test_df_cleaned['completion_count'].apply(lambda x: 1 if x > 0 else 0)\n",
    "control_df_cleaned.loc[:, 'completion_count'] = control_df_cleaned['completion_count'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Step 2: Calculate completions and sample size\n",
    "test_completions = test_df_cleaned['completion_count'].sum()\n",
    "control_completions = control_df_cleaned['completion_count'].sum()\n",
    "\n",
    "test_size = len(test_df_cleaned)\n",
    "control_size = len(control_df_cleaned)\n",
    "\n",
    "# Step 3: Calculate completion rates\n",
    "test_completion_rate = test_completions / test_size\n",
    "control_completion_rate = control_completions / control_size\n",
    "\n",
    "print(f\"Test Group Completion Rate: {test_completion_rate * 100:.2f}%\")\n",
    "print(f\"Control Group Completion Rate: {control_completion_rate * 100:.2f}%\")\n",
    "\n",
    "# Step 4: Check if the completion rates are valid (i.e., between 0 and 1)\n",
    "if test_completion_rate == 0 or test_completion_rate == 1 or control_completion_rate == 0 or control_completion_rate == 1:\n",
    "    print(\"One of the groups has a completion rate of 0 or 1, skipping Z-test.\")\n",
    "else:\n",
    "    # Step 5: Perform Z-test for proportions\n",
    "    p_pooled = (test_completions + control_completions) / (test_size + control_size)\n",
    "    try:\n",
    "        se = np.sqrt(p_pooled * (1 - p_pooled) * (1 / test_size + 1 / control_size))\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in standard error calculation: {e}\")\n",
    "        se = None\n",
    "\n",
    "    if se is not None:\n",
    "        z = (test_completion_rate - control_completion_rate) / se\n",
    "        p_value = 2 * (1 - norm.cdf(abs(z)))\n",
    "\n",
    "        print(f\"Z-score: {z:.2f}\")\n",
    "        print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "        # Step 6: Check if the result is significant\n",
    "        alpha = 0.05  # 95% confidence level\n",
    "\n",
    "        if p_value < alpha:\n",
    "            print(\"The difference between the groups is statistically significant.\")\n",
    "        else:\n",
    "            print(\"The difference between the groups is not statistically significant.\")\n",
    "    else:\n",
    "        print(\"Skipping statistical test due to invalid data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_data = pd.DataFrame({\n",
    "    'Group': ['Test', 'Control'],\n",
    "    'Completion Rate': [test_completion_rate, control_completion_rate]\n",
    "})\n",
    "\n",
    "# Define custom colors\n",
    "test_color = 'royalblue'\n",
    "control_color = 'tomato'\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.barplot(x='Group', y='Completion Rate', data=completion_data, color=test_color)\n",
    "\n",
    "plt.bar(1, control_completion_rate, color=control_color)\n",
    "\n",
    "# Add percentages on top of each bar\n",
    "for i, bar in enumerate(ax.patches):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height + 0.02, f'{height * 100:.2f}%', \n",
    "            ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "plt.title('Completion Rates by Group', fontsize=16)\n",
    "plt.ylabel('Completion Rate', fontsize=12)\n",
    "plt.ylim(0, 1)  # Completion rate should be between 0 and 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Histograms of Completion Counts (Test vs Control)**\n",
    "\n",
    "# Plot histograms to visualize the distribution of completion counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(test_df_cleaned['completion_count'], kde=False, color='red', label='Test Group', bins=3, alpha=0.6, edgecolor='none')\n",
    "sns.histplot(control_df_cleaned['completion_count'], kde=False, color='limegreen', label='Control Group', bins=3, alpha=0.6, edgecolor='none')\n",
    "plt.title('Distribution of Completion Counts by Group', fontsize=16)\n",
    "plt.xlabel('Completion Count (0 or 1)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the margin for the 95% confidence interval\n",
    "confidence_interval_margin = 1.96 * np.sqrt((test_completion_rate * (1 - test_completion_rate) / test_size) + \n",
    "                                            (control_completion_rate * (1 - control_completion_rate) / control_size))\n",
    "\n",
    "# Create a DataFrame for plotting CI\n",
    "ci_data = pd.DataFrame({\n",
    "    'Group': ['Test vs Control'],\n",
    "    'Difference': [test_completion_rate - control_completion_rate],\n",
    "    'CI_Lower': [test_completion_rate - control_completion_rate - confidence_interval_margin],\n",
    "    'CI_Upper': [test_completion_rate - control_completion_rate + confidence_interval_margin]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.barplot(x='Group', y='Difference', data=ci_data, color='indigo', errorbar=None)\n",
    "\n",
    "yerr = np.array([ci_data['Difference'] - ci_data['CI_Lower'], ci_data['CI_Upper'] - ci_data['Difference']])\n",
    "\n",
    "# Use error bars to show the 95% CI\n",
    "plt.errorbar(x=[0], y=ci_data['Difference'], yerr=yerr, fmt='none', color='black', capsize=5)\n",
    "\n",
    "plt.title('Difference in Completion Rates with 95% Confidence Interval', fontsize=16)\n",
    "plt.ylabel('Difference in Completion Rates', fontsize=12)\n",
    "plt.ylim(-0.1, 0.1)  # To visualize the small differences\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Z-Score Plot (Visualizing Statistical Significance)**\n",
    "\n",
    "if se is not None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    z_scores = np.linspace(-4, 4, 100)\n",
    "    p_values = 2 * (1 - norm.cdf(np.abs(z_scores)))\n",
    "\n",
    "    # Plot the Z-score distribution curve\n",
    "    plt.plot(z_scores, p_values, label='Two-tailed p-value', color='purple')\n",
    "    plt.axvline(x=z, color='red', linestyle='--', label=f'Z-score = {z:.2f}')\n",
    "\n",
    "    # Display the p-value threshold (alpha = 0.05)\n",
    "    plt.axhline(y=0.05, color='blue', linestyle='--', label='Significance level (Î± = 0.05)')\n",
    "\n",
    "    plt.title('Z-Score and P-Value Distribution', fontsize=16)\n",
    "    plt.xlabel('Z-Score', fontsize=12)\n",
    "    plt.ylabel('P-Value', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Skipping Z-score plot due to invalid data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusions**\n",
    "\n",
    "Based on the results of the analysis, we can draw the following conclusions:\n",
    "\n",
    "#### Completion Rate Comparison:\n",
    "\n",
    "Test Group Completion Rate: 69.77%\n",
    "Control Group Completion Rate: 65.90%\n",
    "\n",
    "The test group has a higher completion rate compared to the control group. This indicates that the new design (or intervention) in the test group appears to be more effective at driving user completion compared to the existing design in the control group.\n",
    "\n",
    "\n",
    "#### Statistical Significance:\n",
    "\n",
    "Z-score: 9.82\n",
    "P-value: 0.0000\n",
    "\n",
    "The Z-score of 9.82 is significantly high, indicating a large difference between the two groups in terms of completion rate.\n",
    "\n",
    "The P-value is 0.0000, which is much smaller than the typical significance level of 0.05. This means that the observed difference in completion rates between the test and control groups is statistically significant.\n",
    "\n",
    "\n",
    "#### Conclusion on the Hypothesis:\n",
    "\n",
    "The null hypothesis (i.e., there is no difference between the groups) is rejected.\n",
    "The alternative hypothesis (i.e., the test group has a higher completion rate than the control group) is accepted.\n",
    "\n",
    "\n",
    "#### Practical Implication:\n",
    "\n",
    "Since the difference in completion rates is statistically significant, the new design (represented by the test group) is more effective in driving user completions than the old design (control group).\n",
    "\n",
    "The size of the Z-score (9.82) further emphasizes that the difference is not likely due to random chance. The result is strong and robust.\n",
    "\n",
    "\n",
    "#### Confidence Interval for the Difference:\n",
    "\n",
    "Based on the analysis, the 95% confidence interval for the difference in completion rates shows a range that does not include 0, further supporting the conclusion that there is a real and significant difference between the test and control groups.\n",
    "\n",
    "\n",
    "#### Next Steps / Recommendations:\n",
    "\n",
    "Given the statistical significance and the positive impact on completion rates, the test group design should be considered for implementation or further optimization.\n",
    "Cost/Benefit Analysis: While the results are statistically significant, the next step should involve an evaluation of the costs of implementing the new design. If the increase in completion rate (from 65.90% to 69.77%) translates to a substantial increase in revenue or user satisfaction, the new design may be justifiable from a cost-effectiveness perspective.\n",
    "Scale and Monitor: Before a full-scale rollout, it would be wise to monitor the test group in different environments or across additional demographics to ensure consistent results.\n",
    "\n",
    "\n",
    "#### Final Takeaway:\n",
    "\n",
    "The A/B test results show that the test design has a statistically significant and positive impact on the completion rate. Given the strong statistical evidence, it is advisable to move forward with the new design, assuming that the increased completion rate brings tangible benefits and justifies any potential increase in costs associated with the change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
