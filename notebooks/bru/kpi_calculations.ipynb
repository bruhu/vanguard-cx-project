{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb0735c-ea70-496e-99be-0eb48c4f74a0",
   "metadata": {},
   "source": [
    "### Performance Metrics\n",
    "\n",
    "## Success Indicators\n",
    "\n",
    "You have now been asked to discover what key performance indicators (KPIs) will determine the success of the new design? Use at least completion rate, time spent on each step and error rates. Add any KPIs you might find relevant.\n",
    "\n",
    "- **Completion Rate:** The proportion of users who reach the final â€˜confirmâ€™ step.\n",
    "- **Time Spent on Each Step:** The average duration users spend on each step.\n",
    "- **Error Rates:** If thereâ€™s a step where users go back to a previous step, it may indicate confusion or an error. You should consider moving from a later step to an earlier one as an error.\n",
    "\n",
    "## Redesign Outcome\n",
    "\n",
    "Based on the chosen KPIs, how does the new designâ€™s performance compare to the old one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a7b946f-9808-485b-b949-f490ca2654b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6204a9-1829-41ec-bf5a-a719c453abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reusable functions from utils directory\n",
    "import sys\n",
    "sys.path.append('../../utils')\n",
    "import kpi_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03573a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/clean/final_clean_client_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "904ffb23-e226-4a0a-8c48-492339dc7c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dates in the column have the same format.\n"
     ]
    }
   ],
   "source": [
    "df['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')\n",
    "\n",
    "# check if any dates couldn't be converted (i.e., they are NaT)\n",
    "inconsistent_dates = df['date_time'].isna().sum()\n",
    "\n",
    "# if inconsistent_dates > 0, then there are invalid or mismatched date formats\n",
    "if inconsistent_dates > 0:\n",
    "    print(f'There are {inconsistent_dates} inconsistent or invalid date formats in the column.')\n",
    "else:\n",
    "    print('All dates in the column have the same format.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a50673d-d2d3-415b-95dd-a531af3b0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_df = df.copy()\n",
    "kpi_df = kpi_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83d4904-8fb7-487c-88d3-03fa977d4ad1",
   "metadata": {},
   "source": [
    "# **Completion Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ee3fb5-b74e-4fe9-9ec1-19aaa5f92857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients who finished the process: 47787 out of 70594.\n",
      "Completion count (grouped by client_id):\n",
      "   client_id  completion_count\n",
      "0        169                 1\n",
      "1        555                 1\n",
      "2        647                 1\n",
      "3        722                 1\n",
      "4       1195                 1\n",
      "Final DataFrame with completion count:\n",
      "   client_id  completion_count\n",
      "0        169                 1\n",
      "1        169                 1\n",
      "2        169                 1\n",
      "3        169                 1\n",
      "4        169                 1\n"
     ]
    }
   ],
   "source": [
    "def find_completion_rate(df):    \n",
    "    clients_finished = df[df['step'] == 4]\n",
    "    total_unique_clients = df['client_id'].nunique()\n",
    "    unique_clients_finished = clients_finished['client_id'].nunique()\n",
    "    print(f'Clients who finished the process: {unique_clients_finished} out of {total_unique_clients}.')\n",
    "    \n",
    "    completion_count = clients_finished.groupby('client_id').size().reset_index(name='completion_count')\n",
    "    print('Completion count (grouped by client_id):')\n",
    "    print(completion_count.head())\n",
    "    \n",
    "    df = df.merge(completion_count[['client_id', 'completion_count']], on='client_id', how='left') # add completion_count column\n",
    "\n",
    "    df['completion_count'] = df['completion_count'].fillna(0).astype(int) # replace NaN with 0 for clients who never finished\n",
    "    \n",
    "    print('Final DataFrame with completion count:')\n",
    "    print(df[['client_id', 'completion_count']].head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "kpi_df = find_completion_rate(kpi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb40b4a-8c93-414a-bf3b-bc5e0418b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_finished = kpi_df[kpi_df['step'] == 4]['client_id'].nunique()\n",
    "total_clients = kpi_df['client_id'].nunique()\n",
    "clients_not_finished = total_clients - clients_finished\n",
    "\n",
    "completion_rate = (clients_finished / total_clients) * 100\n",
    "\n",
    "# # saved plot\n",
    "# # pie chart\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.pie(\n",
    "#     [clients_finished, clients_not_finished],\n",
    "#     labels=['Finished', 'Not Finished'],\n",
    "#     autopct='%1.1f%%',\n",
    "#     colors=['lightgreen', 'salmon'],\n",
    "#     startangle=140\n",
    "# )\n",
    "# plt.title('Completion Rate')\n",
    "# plt.show()\n",
    "\n",
    "# # saved plot\n",
    "# # bar chart\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# bars = plt.bar(['Total Clients', 'Completed Clients'], [total_clients, clients_finished], color=['lightgreen', 'salmon'])\n",
    "\n",
    "# # add percentage annotation on top\n",
    "# plt.text(1, clients_finished + 1, f'{completion_rate:.1f}%', ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# plt.title('Total Clients vs Completed Clients')\n",
    "# plt.ylabel('Number of Clients')\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0445e92-3c0f-421a-be51-b469e60bf35a",
   "metadata": {},
   "source": [
    "# **Time spent on each step**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db94983",
   "metadata": {},
   "source": [
    "New approach: calculate the time difference between consecutive steps for each client during each visit (this time taking `'visit_id'`):\n",
    "\n",
    "- Sort the Data: Sort by `'client_id'`, `'visit_id'`, and `'step'` to ensure that steps are ordered for each client within each session.\n",
    "- Calculate Time Spent on Each Step: For each `'client_id'` and `'visit_id'`, calculate the difference between the timestamp of the current step and the next step for that client.\n",
    "- Group by `'client_id'` and `'step'`: Calculate the average time spent on each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16c00319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median time spent across all steps: 0.92 minutes\n",
      "   step  overall_avg_time_minutes\n",
      "0     0                      0.00\n",
      "1     1                      0.40\n",
      "2     2                      1.15\n",
      "3     3                      1.70\n",
      "4     4                      0.92\n"
     ]
    }
   ],
   "source": [
    "# Call the function to calculate average time per step for each client\n",
    "time_per_step_df = kpi_functions.calculate_average_time_per_step(kpi_df)\n",
    "\n",
    "# Now, calculate the overall average time per step, regardless of client_id\n",
    "overall_avg_time_per_step = time_per_step_df.groupby('step')['avg_time_minutes'].mean().reset_index(name='overall_avg_time_minutes')\n",
    "\n",
    "# Print the results\n",
    "print(overall_avg_time_per_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e7c7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_name_mapping = {0: 'Start', 1: 'Step 1', 2: 'Step 2', 3: 'Step 3', 4: 'Finish'}\n",
    "time_per_step_df['step_name'] = time_per_step_df['step'].map(step_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "539c4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot saved\n",
    "\n",
    "# Bar plot for average time spent per step (without hue)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(x='step_name', y='avg_time_minutes', data=time_per_step_df, palette='viridis')\n",
    "\n",
    "# plt.title('Average Time Spent per Step', fontsize=16)\n",
    "# plt.xlabel('Step', fontsize=12)\n",
    "# plt.ylabel('Time (minutes)', fontsize=12)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbf258b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot saved\n",
    "# Line plot for time spent across steps (can be useful to see trends)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(x='step_name', y='avg_time_minutes', data=time_per_step_df, marker='o', color='blue')\n",
    "# plt.title('Average Time Spent per Step', fontsize=16)\n",
    "# plt.xlabel('Step', fontsize=12)\n",
    "# plt.ylabel('Time (minutes)', fontsize=12)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d977920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot saved\n",
    "# Box plot to show distribution of time spent per step\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.boxplot(x='step_name', y='avg_time_minutes', data=time_per_step_df)\n",
    "# plt.title('Distribution of Time Spent per Step', fontsize=16)\n",
    "# plt.xlabel('Step', fontsize=12)\n",
    "# plt.ylabel('Time (minutes)', fontsize=12)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f1198-4369-4f69-a799-405b1949aced",
   "metadata": {},
   "source": [
    "# **Error Rates**\n",
    "_(Constanza's code, taking `visit_id` into account)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3d72970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop existing columns to replace the values\n",
    "kpi_df = kpi_df.drop(columns=['stepped_back', 'error_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d7244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error count per step: 0.08\n",
      "Total error count per client:\n",
      "client_id\n",
      "169    0\n",
      "555    0\n",
      "647    0\n",
      "722    2\n",
      "934    0\n",
      "Name: stepped_back, dtype: int64\n",
      "Error rate (clients with errors): 29.95%\n",
      "Error rate (steps with errors): 8.13%\n",
      "Error rate per step: 8.13%\n",
      "   client_id             visitor_id                      visit_id  step  \\\n",
      "4        169  201385055_71273495308  749567106_99161211863_557568     0   \n",
      "3        169  201385055_71273495308  749567106_99161211863_557568     1   \n",
      "2        169  201385055_71273495308  749567106_99161211863_557568     2   \n",
      "1        169  201385055_71273495308  749567106_99161211863_557568     3   \n",
      "0        169  201385055_71273495308  749567106_99161211863_557568     4   \n",
      "\n",
      "            date_time  tenure_years  tenure_months  age gender  accounts  \\\n",
      "4 2017-04-12 20:19:36            21            262   47   Male         2   \n",
      "3 2017-04-12 20:19:45            21            262   47   Male         2   \n",
      "2 2017-04-12 20:20:31            21            262   47   Male         2   \n",
      "1 2017-04-12 20:22:05            21            262   47   Male         2   \n",
      "0 2017-04-12 20:23:09            21            262   47   Male         2   \n",
      "\n",
      "     balance  calls_last_6_months  logons_last_6_months variation  \\\n",
      "4  501570.72                    4                     4   Unknown   \n",
      "3  501570.72                    4                     4   Unknown   \n",
      "2  501570.72                    4                     4   Unknown   \n",
      "1  501570.72                    4                     4   Unknown   \n",
      "0  501570.72                    4                     4   Unknown   \n",
      "\n",
      "   completion_count  stepped_back  error_rate_per_step  \n",
      "4                 1         False                  0.0  \n",
      "3                 1         False                  0.0  \n",
      "2                 1         False                  0.0  \n",
      "1                 1         False                  0.0  \n",
      "0                 1         False                  0.0  \n"
     ]
    }
   ],
   "source": [
    "def calculate_error_count(df):\n",
    "    df = df.sort_values(by=['client_id', 'visit_id', 'date_time'])\n",
    "\n",
    "    # backward steps (errors) for each client within each visit\n",
    "    df['stepped_back'] = df.groupby(['client_id', 'visit_id'])['step'].diff() < 0\n",
    "\n",
    "    # Calculate total errors (total backward steps)\n",
    "    total_errors = df['stepped_back'].sum()\n",
    "\n",
    "    # total steps (rows in the dataframe)\n",
    "    total_steps = len(df)\n",
    "\n",
    "    # average error count per step (percentage of steps that are errors)\n",
    "    avg_error_count_per_step = df['stepped_back'].mean()  # This gives the average proportion of steps that are errors\n",
    "    print(f'Average error count per step: {avg_error_count_per_step:.2f}')\n",
    "\n",
    "    # total error count per client (sum of backward steps per client)\n",
    "    total_errors_per_client = df.groupby('client_id')['stepped_back'].sum()\n",
    "    print(f'Total error count per client:\\n{total_errors_per_client.head()}')\n",
    "\n",
    "    # unique clients with errors\n",
    "    clients_with_errors = (total_errors_per_client > 0).sum()\n",
    "    error_rate_clients = (clients_with_errors / df['client_id'].nunique()) * 100\n",
    "    print(f'Error rate (clients with errors): {error_rate_clients:.2f}%')\n",
    "\n",
    "    # percentage of total steps that have errors\n",
    "    error_rate_steps = (total_errors / total_steps) * 100  # % of steps that are errors\n",
    "    print(f'Error rate (steps with errors): {error_rate_steps:.2f}%')\n",
    "\n",
    "    # error rate per step (the proportion of steps that are errors)\n",
    "    df['error_rate_per_step'] = df['stepped_back'].astype(int) / 1  # each row represents a step, so this is either 0 or 1\n",
    "    error_rate_per_step = df['error_rate_per_step'].mean() * 100  # mean error rate per step\n",
    "    print(f'Error rate per step: {error_rate_per_step:.2f}%')\n",
    "\n",
    "    return df, total_errors_per_client\n",
    "\n",
    "kpi_df, total_errors_per_client = calculate_error_count(kpi_df)\n",
    "print(kpi_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8004d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved plot\n",
    "\n",
    "# # Plot: Error Rate (Clients with Errors) as a percentage\n",
    "# clients_with_errors = (total_errors_per_client > 0).sum()  # Clients with at least 1 error\n",
    "# total_clients = kpi_df['client_id'].nunique()  # Total number of unique clients\n",
    "# error_rate_clients = (clients_with_errors / total_clients) * 100\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.pie([error_rate_clients, 100 - error_rate_clients], labels=['Clients With Errors', 'Clients with No Errors'], \n",
    "#         colors=['khaki', 'steelblue'], autopct='%1.1f%%', startangle=90)\n",
    "# plt.title('Error Rate (Clients with Steps Back)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14e3194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved plot\n",
    "\n",
    "# # Line Plot with Average Errors per Step\n",
    "\n",
    "# kpi_df['stepped_back'] = kpi_df.groupby(['client_id', 'visit_id'])['step'].diff() < 0\n",
    "\n",
    "# # error rate (step-back rate) for each step\n",
    "# step_error_rate = kpi_df.groupby('step')['stepped_back'].mean() * 100  # Percentage of clients with step back at each step\n",
    "\n",
    "# # round error rates to whole numbers (no decimals)\n",
    "# step_error_rate = step_error_rate.round(0)\n",
    "\n",
    "# step_labels = {\n",
    "#     0: 'Start', \n",
    "#     1: 'Step 1', \n",
    "#     2: 'Step 2', \n",
    "#     3: 'Step 3', \n",
    "#     4: 'Finish' \n",
    "# }\n",
    "\n",
    "# # use the step labels instead of numeric values\n",
    "# step_error_rate.index = step_error_rate.index.map(step_labels)\n",
    "\n",
    "# # average error rate\n",
    "# avg_error_rate = step_error_rate.mean()\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# #  error rate for each step\n",
    "# plt.plot(step_error_rate.index, step_error_rate.values, marker='o', color='orange', label='Step Back Rate', linestyle='-', alpha=0.7)\n",
    "\n",
    "# # average error rate as a horizontal line\n",
    "# plt.axhline(y=avg_error_rate, color='steelblue', linestyle='--', label=f'Average Step Back Rate: {avg_error_rate:.0f}%')\n",
    "\n",
    "# plt.title('Error Rate for Each Step')\n",
    "# plt.xlabel('Step')\n",
    "# plt.ylabel('Rate (%)')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370564ca-ade9-405c-87f2-a7340575fc4e",
   "metadata": {},
   "source": [
    "# **Redesign Outcome**\n",
    "Based on the chosen KPIs, how does the new designâ€™s performance compare to the old one?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63240691-8863-4d87-a26a-399aaf59f14a",
   "metadata": {},
   "source": [
    "For the project requirements and instructions for todayâ€™s tasks in full, please refer to the project brief. However, in order to keep on track you may refer to the daily goals outlined below:\n",
    "\n",
    "By the end of day, we recommend you have:\n",
    "\n",
    "Reviewed KPI and Metrics material.\n",
    "Discovered what key performance indicators (KPIs) will determine the success of the new design\n",
    "Use at least completion rate, time spent on each step and error rates. Add any KPIs you might find relevant.\n",
    "Evaluated how the new designâ€™s performance compare to the old one, given the chosen KPIs (completion rate, time spent on each step and error rates)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d472b47d-6841-4130-9781-5bec0a60b4c8",
   "metadata": {},
   "source": [
    "### Evaluate how the new designâ€™s performance compare to the old one, given the chosen KPIs \n",
    "- Completion rate\n",
    "- Time spent on each step\n",
    "- Error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8915b4a0-a698-4014-992a-7e2d754176fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in dfs for each variation\n",
    "test_variation_df = kpi_df[kpi_df['variation'] == 'Test']\n",
    "control_variation_df = kpi_df[kpi_df['variation'] == 'Control']\n",
    "unknown_variation_df = kpi_df[kpi_df['variation'] == 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f20dad-5b08-4d09-9a52-1f135c1a2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop empty rows\n",
    "test_variation_df = test_variation_df.dropna()\n",
    "control_variation_df = control_variation_df.dropna()\n",
    "unknown_variation_df = unknown_variation_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed7bbbf",
   "metadata": {},
   "source": [
    "Convert to `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e23d0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kpi_df.to_csv('kpi_df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6deddc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_variation_df.to_csv('test_variation_df_clean.csv')\n",
    "# control_variation_df.to_csv('control_variation_df.csv')\n",
    "# unknown_variation_df.to_csv('unknown_variation_df_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d86abe-d5b7-4305-9326-396877ed4f06",
   "metadata": {},
   "source": [
    "## Completion Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03afec82-18b3-48c7-8586-78c1abe45e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion rate for Control:\n",
      "Clients who finished the process: 15428 out ouf 23526.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15428, 23526, 0.6557850888378814)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nCompletion rate for Control:')\n",
    "kpi_functions.find_completion_rate(control_variation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "795b51e3-daa5-4c30-aad4-e05ba13e6b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion rate for Test:\n",
      "Clients who finished the process: 18682 out ouf 26961.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18682, 26961, 0.6929268202218019)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nCompletion rate for Test:')\n",
    "kpi_functions.find_completion_rate(test_variation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c3535b-599b-4895-bf82-bffb56d500b3",
   "metadata": {},
   "source": [
    "## Time spent on each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17f4d595-3ed5-4df1-a379-5f76a6167269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median time spent across all steps: 1.18 minutes\n",
      "Average Time Spent Per Step:\n",
      "   step  avg_time_minutes\n",
      "0     0              0.00\n",
      "1     1              0.40\n",
      "2     2              1.15\n",
      "3     3              1.70\n",
      "4     4              0.92\n"
     ]
    }
   ],
   "source": [
    "kpi_functions.calculate_average_time_per_step(test_variation_df)\n",
    "print('Average Time Spent Per Step:')\n",
    "print(time_per_step_df[['step', 'avg_time_minutes']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e25db30-2a57-4113-8b2d-4bd6d9bdc9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median time spent across all steps: 0.88 minutes\n",
      "\n",
      "Average Time Spent Per Step:\n",
      "   step  avg_time_minutes\n",
      "0     0              0.00\n",
      "1     1              0.40\n",
      "2     2              1.15\n",
      "3     3              1.70\n",
      "4     4              0.92\n"
     ]
    }
   ],
   "source": [
    "kpi_functions.calculate_average_time_per_step(control_variation_df)\n",
    "print('\\nAverage Time Spent Per Step:')\n",
    "print(time_per_step_df[['step', 'avg_time_minutes']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3894d-5966-4c3c-abe9-f57038d90419",
   "metadata": {},
   "source": [
    "## Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76eb7a85-21fe-4083-b43c-54caccf44306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors per client: client_id\n",
      "1346       2\n",
      "1516       3\n",
      "1643       1\n",
      "1836       1\n",
      "1936       1\n",
      "          ..\n",
      "9994764    6\n",
      "9995295    3\n",
      "9998156    1\n",
      "9999150    1\n",
      "9999729    1\n",
      "Length: 9009, dtype: int64\n",
      "Total number of errors across all clients: 16229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9009,\n",
       " client_id\n",
       " 1346       2\n",
       " 1516       3\n",
       " 1643       1\n",
       " 1836       1\n",
       " 1936       1\n",
       "           ..\n",
       " 9994764    6\n",
       " 9995295    3\n",
       " 9998156    1\n",
       " 9999150    1\n",
       " 9999729    1\n",
       " Length: 9009, dtype: int64,\n",
       " np.int64(16229))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpi_functions.find_error_rate(test_variation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d914c14-ed2a-4cc9-99bb-8debe4bdfae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors per client: client_id\n",
      "1028       2\n",
      "1197       1\n",
      "3647       1\n",
      "7020       3\n",
      "9229       3\n",
      "          ..\n",
      "9995084    1\n",
      "9995265    1\n",
      "9997391    2\n",
      "9997470    3\n",
      "9998346    1\n",
      "Length: 6137, dtype: int64\n",
      "Total number of errors across all clients: 9576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6137,\n",
       " client_id\n",
       " 1028       2\n",
       " 1197       1\n",
       " 3647       1\n",
       " 7020       3\n",
       " 9229       3\n",
       "           ..\n",
       " 9995084    1\n",
       " 9995265    1\n",
       " 9997391    2\n",
       " 9997470    3\n",
       " 9998346    1\n",
       " Length: 6137, dtype: int64,\n",
       " np.int64(9576))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpi_functions.find_error_rate(control_variation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9ab53ec-3913-4b47-8363-4b085e3222a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors per client: client_id\n",
      "722        2\n",
      "1677       1\n",
      "2078       3\n",
      "8583       1\n",
      "9536       1\n",
      "          ..\n",
      "9993293    4\n",
      "9996478    2\n",
      "9996952    2\n",
      "9998430    1\n",
      "9998980    1\n",
      "Length: 6000, dtype: int64\n",
      "Total number of errors across all clients: 10267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6000,\n",
       " client_id\n",
       " 722        2\n",
       " 1677       1\n",
       " 2078       3\n",
       " 8583       1\n",
       " 9536       1\n",
       "           ..\n",
       " 9993293    4\n",
       " 9996478    2\n",
       " 9996952    2\n",
       " 9998430    1\n",
       " 9998980    1\n",
       " Length: 6000, dtype: int64,\n",
       " np.int64(10267))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpi_functions.find_error_rate(unknown_variation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41821b1-3c3c-47c2-8435-69820bb96018",
   "metadata": {},
   "source": [
    "# Storing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7deff483-2cc5-4650-a571-1b29ffd76f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients who finished the process: 18682 out ouf 26961.\n",
      "Clients who finished the process: 18682 out ouf 26961.\n",
      "Errors per client: client_id\n",
      "1346       2\n",
      "1516       3\n",
      "1643       1\n",
      "1836       1\n",
      "1936       1\n",
      "          ..\n",
      "9994764    6\n",
      "9995295    3\n",
      "9998156    1\n",
      "9999150    1\n",
      "9999729    1\n",
      "Length: 9009, dtype: int64\n",
      "Total number of errors across all clients: 16229\n",
      "Clients who finished the process: 15428 out ouf 23526.\n",
      "Clients who finished the process: 15428 out ouf 23526.\n",
      "Errors per client: client_id\n",
      "1028       2\n",
      "1197       1\n",
      "3647       1\n",
      "7020       3\n",
      "9229       3\n",
      "          ..\n",
      "9995084    1\n",
      "9995265    1\n",
      "9997391    2\n",
      "9997470    3\n",
      "9998346    1\n",
      "Length: 6137, dtype: int64\n",
      "Total number of errors across all clients: 9576\n",
      "Clients who finished the process: 13677 out ouf 20107.\n",
      "Clients who finished the process: 13677 out ouf 20107.\n",
      "Errors per client: client_id\n",
      "722        2\n",
      "1677       1\n",
      "2078       3\n",
      "8583       1\n",
      "9536       1\n",
      "          ..\n",
      "9993293    4\n",
      "9996478    2\n",
      "9996952    2\n",
      "9998430    1\n",
      "9998980    1\n",
      "Length: 6000, dtype: int64\n",
      "Total number of errors across all clients: 10267\n"
     ]
    }
   ],
   "source": [
    "# store the results for test df\n",
    "test_unique_finished, test_total_clients, test_completion_rate = kpi_functions.find_completion_rate(test_variation_df)\n",
    "test_avg_time_per_step = kpi_functions.find_completion_rate(test_variation_df)\n",
    "test_clients_with_errors, test_errors_per_client, test_total_errors = kpi_functions.find_error_rate(test_variation_df)\n",
    "\n",
    "# store the results for control df\n",
    "control_unique_finished, control_total_clients, control_completion_rate = kpi_functions.find_completion_rate(control_variation_df)\n",
    "control_avg_time_per_step = kpi_functions.find_completion_rate(control_variation_df)\n",
    "control_clients_with_errors, control_errors_per_client, control_total_errors = kpi_functions.find_error_rate(control_variation_df)\n",
    "\n",
    "# store the results for unknown df\n",
    "unknown_finished, unknown_total_clients, unknown_completion_rate = kpi_functions.find_completion_rate(unknown_variation_df)\n",
    "unknown_avg_time_per_step = kpi_functions.find_completion_rate(unknown_variation_df)\n",
    "unknown_clients_with_errors, unknown_errors_per_client, unknown_total_errors = kpi_functions.find_error_rate(unknown_variation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d548c2",
   "metadata": {},
   "source": [
    "## **Completion Rate with a Cost-Effectiveness Threshold**\n",
    "\n",
    "Null Hypothesis (\\(H_0\\)): The completion rate for the Test group (new design) is equal to or greater than the completion rate for the Control group (old design) increased by 5%.\n",
    "Alternative Hypothesis (\\(H_a\\)): The completion rate for the Test group (new design) is lower than the completion rate for the Control group (old design) increased by 5%.\n",
    "\n",
    "\\[ H_{0}: \\hat_{p}_{1} - \\hat_{p}_{2} < 0.05 \\]\n",
    "\n",
    "Note: a one-sided two-proportion z-test is appropriate.\n",
    "\n",
    "*Specifically, your ð»0 and ð»ð‘Ž involve testing if the completion rate of the Test group is less than the Control group increased by 5%, and the formula for ð‘ incorporates a threshold adjustment of 0.05.*\n",
    "\n",
    "Given the new threshold, you will compare the completion rate of the Test group to the completion rate of the Control group increased by 5%. Therefore, now the formula for the Z statistic is given by:\n",
    "\n",
    "\\[ Z = \\frac{( \\hat{p}_{1} - \\hat{p}_{2} - \\color{red}{0.05}\\color{black} )}{ \\sqrt{ \\hat{p} (1 - \\hat{p} ) \\left( \\frac{1}{n_{1}} + \\frac{1}{n_{2}} \\right)} } \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af69e39",
   "metadata": {},
   "source": [
    "## Hypotheses\n",
    "\n",
    "**Null Hypothesis (\\(H_0\\))**:  \n",
    "The completion rate for the Test group (new design) is equal to or greater than the completion rate for the Control group (old design) increased by 5%.\n",
    "\n",
    "**Alternative Hypothesis (\\(H_a\\))**:  \n",
    "The completion rate for the Test group (new design) is lower than the completion rate for the Control group (old design) increased by 5%.\n",
    "\n",
    "\\[\n",
    "H_{0}: \\hat{p}_{1} - \\hat{p}_{2} < 0.05\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### Important Notes:\n",
    "Specifically, your \\(H_0\\) and \\(H_a\\) involve testing if the completion rate of the Test group is **less than the Control group increased by 5%**, and the formula for \\(Z\\) incorporates a threshold adjustment of \\(0.05\\).\n",
    "\n",
    "### Z-Statistic Formula:\n",
    "\n",
    "\\[\n",
    "Z = \\frac{\\left( \\hat{p}_{1} - \\hat{p}_{2} - \\color{red}{0.05} \\color{black} \\right)}{\\sqrt{\\hat{p} \\cdot (1 - \\hat{p}) \\cdot \\left( \\frac{1}{n_{1}} + \\frac{1}{n_{2}} \\right)}}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of Terms:\n",
    "- \\(\\hat{p}_{1}\\): Proportion of successes in the Test group.\n",
    "- \\(\\hat{p}_{2}\\): Proportion of successes in the Control group.\n",
    "- \\(0.05\\): The threshold adjustment in the null hypothesis.\n",
    "- \\(\\hat{p}\\): Pooled proportion:\n",
    "  \\[\n",
    "  \\hat{p} = \\frac{\\text{Total successes in both groups}}{\\text{Total observations in both groups}}\n",
    "  \\]\n",
    "- \\(n_{1}, n_{2}\\): Sample sizes of the Test and Control groups, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8b15108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients who finished the process: 18682 out ouf 26961.\n",
      "Clients who finished the process: 18682 out ouf 26961.\n",
      "Errors per client: client_id\n",
      "1346       2\n",
      "1516       3\n",
      "1643       1\n",
      "1836       1\n",
      "1936       1\n",
      "          ..\n",
      "9994764    6\n",
      "9995295    3\n",
      "9998156    1\n",
      "9999150    1\n",
      "9999729    1\n",
      "Length: 9009, dtype: int64\n",
      "Total number of errors across all clients: 16229\n",
      "Clients who finished the process: 15428 out ouf 23526.\n",
      "Clients who finished the process: 15428 out ouf 23526.\n",
      "Errors per client: client_id\n",
      "1028       2\n",
      "1197       1\n",
      "3647       1\n",
      "7020       3\n",
      "9229       3\n",
      "          ..\n",
      "9995084    1\n",
      "9995265    1\n",
      "9997391    2\n",
      "9997470    3\n",
      "9998346    1\n",
      "Length: 6137, dtype: int64\n",
      "Total number of errors across all clients: 9576\n"
     ]
    }
   ],
   "source": [
    "# store the results for test df\n",
    "test_unique_finished, test_total_clients, test_completion_rate = kpi_functions.find_completion_rate(test_variation_df)\n",
    "test_avg_time_per_step = kpi_functions.find_completion_rate(test_variation_df)\n",
    "test_clients_with_errors, test_errors_per_client, test_total_errors = kpi_functions.find_error_rate(test_variation_df)\n",
    "\n",
    "# store the results for control df\n",
    "control_unique_finished, control_total_clients, control_completion_rate = kpi_functions.find_completion_rate(control_variation_df)\n",
    "control_avg_time_per_step = kpi_functions.find_completion_rate(control_variation_df)\n",
    "control_clients_with_errors, control_errors_per_client, control_total_errors = kpi_functions.find_error_rate(control_variation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1baacc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion rate for Control: 0.6558\n",
      "Control completion rate (from var): 0.6557850888378814\n",
      "Completion rate for Test: 0.6929\n",
      "Test completion rate (from var): 0.6929268202218019\n",
      "Z-statistic: -3.0786\n",
      "P-value: 0.0010\n"
     ]
    }
   ],
   "source": [
    "success_control = control_unique_finished\n",
    "total_control = control_total_clients\n",
    "\n",
    "success_test = test_unique_finished\n",
    "total_test = test_total_clients\n",
    "\n",
    "# calc proportions\n",
    "p_control = success_control / total_control #completion rate for control group\n",
    "p_test = success_test / total_test #completion rate for test group \n",
    "p_combined = (success_control + success_test) / (total_control + total_test)  # pooled proportion\n",
    "\n",
    "# adjust for 5% threshold\n",
    "threshold = 0.05\n",
    "z_stat = (p_test - p_control - threshold) / np.sqrt(p_combined * (1 - p_combined) * (1 / total_control + 1 / total_test))\n",
    "\n",
    "# calc the one-sided p_value\n",
    "p_value = norm.cdf(z_stat)  # use the cumulative distribution function for one-sided p-value\n",
    "\n",
    "print(f'Completion rate for Control: {p_control:.4f}')\n",
    "print(f'Control completion rate (from var): {control_completion_rate}')\n",
    "print(f'Completion rate for Test: {p_test:.4f}')\n",
    "print(f'Test completion rate (from var): {test_completion_rate}')\n",
    "print(f'Z-statistic: {z_stat:.4f}')\n",
    "print(f'P-value: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d419982-5573-4213-8f18-bfb14e4f3986",
   "metadata": {},
   "source": [
    "## **Testing Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff445bf-1ed2-44a7-84aa-d39a423b0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_completion_rate(test_completion_rate, control_completion_rate):\n",
    "#     completion_rate_data = {\n",
    "#         'Version': ['Test', 'Control'],\n",
    "#         'Completion Rate': [test_completion_rate, control_completion_rate]\n",
    "#     }\n",
    "#     completion_rate_df = pd.DataFrame(completion_rate_data)\n",
    "    \n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     ax = sns.barplot(x='Version', y='Completion Rate', data=completion_rate_df)\n",
    "    \n",
    "#     ax.patches[0].set_facecolor('lightblue')\n",
    "#     ax.patches[1].set_facecolor('salmon')\n",
    "\n",
    "#     plt.title('Completion Rate (Test vs Control)', fontsize=16)\n",
    "#     plt.ylabel('Rate (%)')\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd6f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot saved\n",
    "# plot_completion_rate(test_completion_rate, control_completion_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261ab27-bd61-4faf-82fd-2492312c9afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_error_rate(test_clients_with_errors, control_clients_with_errors, test_total_errors, control_total_errors):\n",
    "#     clients_error_data = {\n",
    "#         'Variation': ['Test', 'Control'],\n",
    "#         'Clients': [test_clients_with_errors, control_clients_with_errors]\n",
    "#     }\n",
    "#     clients_error_df = pd.DataFrame(clients_error_data)\n",
    "    \n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     ax = sns.barplot(x='Variation', y='Clients', data=clients_error_df)\n",
    "    \n",
    "#     ax.patches[0].set_facecolor('cadetblue')\n",
    "#     ax.patches[1].set_facecolor('lightcoral')    \n",
    "    \n",
    "#     plt.title('Error Count per Client (Test vs Control)', fontsize=16)\n",
    "#     plt.show()\n",
    "\n",
    "#     total_errors_data = {\n",
    "#         'Variation': ['Test', 'Control'],\n",
    "#         'Total Errors': [test_total_errors, control_total_errors]\n",
    "#     }\n",
    "#     total_errors_df = pd.DataFrame(total_errors_data)\n",
    "    \n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     ax = sns.barplot(x='Variation', y='Total Errors', data=total_errors_df)\n",
    "    \n",
    "#     ax.patches[0].set_facecolor('cadetblue')\n",
    "#     ax.patches[1].set_facecolor('lightcoral')    \n",
    "    \n",
    "#     plt.title('Error Count per Variation (Test vs Control)', fontsize=16)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d953d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots saved\n",
    "# plot_error_rate(test_clients_with_errors, control_clients_with_errors, test_total_errors, control_total_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e339d1-dd3c-4b60-a556-8e0a90d73d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Completion Rate Comparison - Pie Chart**\n",
    "\n",
    "def plot_completion_rate_pie(test_completion_rate, control_completion_rate, unknown_completion_rate):\n",
    "    completion_rate_data = {\n",
    "        'Version': ['Test', 'Control', 'Unknown'],\n",
    "        'Completion Rate': [test_completion_rate, control_completion_rate, unknown_completion_rate]\n",
    "    }\n",
    "    completion_rate_df = pd.DataFrame(completion_rate_data)\n",
    "    \n",
    "    # Pie chart\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(completion_rate_df['Completion Rate'], labels=completion_rate_df['Version'], autopct='%1.1f%%', startangle=90, colors=['lightblue', 'salmon', 'lightgray'])\n",
    "    plt.title('Completion Rate (Test, Control and Unknown Variation)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afde5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot saved\n",
    "plot_completion_rate_pie(test_completion_rate, control_completion_rate, unknown_completion_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ca4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_error_rate_df(df):\n",
    "    total_errors_per_client = df[df['stepped_back']].groupby('client_id').size()\n",
    "\n",
    "    total_actions_per_client = df.groupby('client_id').size()\n",
    "\n",
    "    error_rate = total_errors_per_client / total_actions_per_client\n",
    "\n",
    "    error_rate_df = pd.DataFrame({\n",
    "        'client_id': total_actions_per_client.index,\n",
    "        'total_errors': total_errors_per_client,\n",
    "        'total_actions': total_actions_per_client,\n",
    "        'error_rate': error_rate\n",
    "    })\n",
    "\n",
    "    error_rate_df['total_errors'] = error_rate_df['total_errors'].fillna(0).astype(int)\n",
    "    error_rate_df['error_rate'] = error_rate_df['error_rate'].fillna(0).round(2)\n",
    "\n",
    "    error_rate_df['error_percentage'] = error_rate_df['error_rate'] * 100\n",
    "\n",
    "    error_rate_df['has_error'] = error_rate_df['total_errors'] > 0\n",
    "\n",
    "\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['hour'] = pd.to_datetime(df['timestamp']).dt.hour\n",
    "        error_frequency = df[df['stepped_back']].groupby(['client_id', 'hour']).size().unstack(fill_value=0)\n",
    "        error_rate_df['avg_hourly_errors'] = error_frequency.mean(axis=1)\n",
    "\n",
    "    return error_rate_df\n",
    "\n",
    "\n",
    "error_rate_df = generate_error_rate_df(kpi_df)\n",
    "\n",
    "print(error_rate_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c16a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot saved\n",
    "\n",
    "# # Pie chart of Clients with Errors vs. Clients Without Errors\n",
    "# clients_with_errors = error_rate_df[error_rate_df['has_error']]['client_id'].nunique()\n",
    "# clients_without_errors = error_rate_df[~error_rate_df['has_error']]['client_id'].nunique()\n",
    "\n",
    "# labels = ['Clients with Errors', 'Clients without Errors']\n",
    "# sizes = [clients_with_errors, clients_without_errors]\n",
    "# colors = ['#ff9999','#66b3ff']\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=colors, explode=(0.1, 0))\n",
    "# plt.title('Clients with and without Errors')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
